{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04696287 0.03980942 0.03228774 0.02568076 0.02559692 0.02475311\n",
      " 0.02225295 0.02086771 0.01987149 0.0180346  0.01605162 0.01488606\n",
      " 0.01323728 0.0129047  0.0124786  0.01224979 0.0111334  0.01036508\n",
      " 0.00966083 0.0095945  0.00955473 0.00836236]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import yaml\n",
    "import ast\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from pprgo import utils\n",
    "from pprgo import ppr\n",
    "from pprgo import pprgo\n",
    "\n",
    "import igraph\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logger = logging.getLogger()\n",
    "logger.handlers = []\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        fmt='%(asctime)s (%(levelname)s): %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --show-progress -O data/reddit.npz https://ndownloader.figshare.com/files/23742119"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_demo.yaml', 'r') as c:\n",
    "    config = yaml.safe_load(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For strings that yaml doesn't parse (e.g. None)\n",
    "for key, val in config.items():\n",
    "    if type(val) is str:\n",
    "        try:\n",
    "            config[key] = ast.literal_eval(val)\n",
    "        except (ValueError, SyntaxError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file           = config['data_file']           # Path to the .npz data file\n",
    "data_file = 'data/cora_full.npz'\n",
    "# data_file = 'data/reddit.npz'\n",
    "\n",
    "split_seed          = config['split_seed']          # Seed for splitting the dataset into train/val/test\n",
    "ntrain_div_classes  = config['ntrain_div_classes']  # Number of training nodes divided by number of classes\n",
    "attr_normalization  = config['attr_normalization']  # Attribute normalization. Not used in the paper\n",
    "\n",
    "alpha               = config['alpha']               # PPR teleport probability\n",
    "alpha = 0.25\n",
    "eps                 = config['eps']                 # Stopping threshold for ACL's ApproximatePR\n",
    "topk                = config['topk']                # Number of PPR neighbors for each node\n",
    "topk=64\n",
    "ppr_normalization   = config['ppr_normalization']   # Adjacency matrix normalization for weighting neighbors\n",
    "\n",
    "hidden_size         = config['hidden_size']         # Size of the MLP's hidden layer\n",
    "nlayers             = config['nlayers']             # Number of MLP layers\n",
    "weight_decay        = config['weight_decay']        # Weight decay used for training the MLP\n",
    "dropout             = config['dropout']             # Dropout used for training\n",
    "\n",
    "lr                  = config['lr']                  # Learning rate\n",
    "max_epochs          = config['max_epochs']          # Maximum number of epochs (exact number if no early stopping)\n",
    "batch_size          = config['batch_size']          # Batch size for training\n",
    "batch_mult_val      = config['batch_mult_val']      # Multiplier for validation batch size\n",
    "\n",
    "eval_step           = config['eval_step']           # Accuracy is evaluated after every this number of steps\n",
    "run_val             = config['run_val']             # Evaluate accuracy on validation set during training\n",
    "\n",
    "early_stop          = config['early_stop']          # Use early stopping\n",
    "patience            = config['patience']            # Patience for early stopping\n",
    "\n",
    "nprop_inference     = config['nprop_inference']     # Number of propagation steps during inference\n",
    "inf_fraction        = config['inf_fraction']        # Fraction of nodes for which local predictions are computed during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "shape attibute matrix:  18800\n",
      "Training:  1400\n",
      "Validation:  14000\n",
      "Testing:  3400\n",
      "train_idx:  [   12    16    18 ... 18790 18793 18798]\n",
      "Runtime: 0.39s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "(adj_matrix, attr_matrix, labels,\n",
    " train_idx, val_idx, test_idx) = utils.get_data(\n",
    "        f\"{data_file}\",\n",
    "        seed=split_seed,\n",
    "        ntrain_div_classes=ntrain_div_classes,\n",
    "        normalize_attr=attr_normalization\n",
    ")\n",
    "try:\n",
    "    d = attr_matrix.n_columns\n",
    "except AttributeError:\n",
    "    d = attr_matrix.shape[1]\n",
    "nc = labels.max() + 1\n",
    "print(nc)\n",
    "\n",
    "print('shape attibute matrix: ', attr_matrix.n_rows)\n",
    "print('Training: ', len(train_idx))\n",
    "print('Validation: ', len(val_idx))\n",
    "print('Testing: ', len(test_idx))\n",
    "\n",
    "print('train_idx: ', train_idx)\n",
    "\n",
    "time_loading = time.time() - start\n",
    "print(f\"Runtime: {time_loading:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: Calculate PPR scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /Users/arielo97/Documents/University-TOPUSH/Intership/Experiments/internship_env/lib/python3.7/site-packages (2.6.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import from_scipy_sparse_matrix, k_truss, core_number\n",
    "\n",
    "g_networkX = from_scipy_sparse_matrix(adj_matrix)\n",
    "# core_numbers = core_number(g_networkX)\n",
    "# np.save('core-numbers-networkx', np.array(list(core_numbers.values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "truss = k_truss(g_networkX, 3)\n",
    "# print(truss.nodes[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute core numbers\n",
    "core_numbers = np.load('core-numbers-networkx.npy')\n",
    "\n",
    "# graph = igraph.Graph.Adjacency((adj_matrix.todense()> 0).tolist())\n",
    "# core_numbers = np.array(graph.coreness())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('graph.pkl', 'wb') as outp:  # Overwrites any existing file.\n",
    "#         pickle.dump(graph, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('graph.pkl', 'rb') as inp:\n",
    "    graph = pickle.load(inp)\n",
    "\n",
    "# shortest_path = graph.get_shortest_paths(0, to=[1,2,3])\n",
    "# print(shortest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRE n_best:  922\n",
      "idx_key_nodes:  (922,)\n",
      "indptr - 1  18800\n",
      "nodes with page rank:  [18496, 2537, 91, 12]\n",
      "For node:  0\n",
      "j_np:  [13463, 15329, 12809, 111, 14892, 18477, 12487, 13757, 13464, 12681, 4646, 10679, 10332, 5088, 20, 112, 17540, 13893, 15397, 131, 95, 144, 16455, 5779, 14054, 187, 14903, 12690, 139, 71, 15242, 45, 102, 118, 4223, 94, 22, 117, 88, 17541, 4455, 171, 2648, 2649, 18519, 47, 14953, 74, 13131, 11789, 169, 105, 13908, 2152, 18479, 15330, 2474, 98, 77, 113, 16624, 15640, 76, 15388, 2651, 7820, 1872, 3859, 15710, 158, 10963, 12297, 18, 2611, 12374, 4647, 184, 134, 157, 3421, 5237, 4629, 1286, 13339, 1634, 4472, 83, 2557, 40, 18436, 38, 644, 3688, 2650, 4428, 16393, 2643, 185, 7702, 12691, 1789, 520, 4772, 5076, 13742, 107, 4919, 4773, 114, 844, 165, 56, 6570, 13338, 104, 8417, 129, 163, 5071, 127, 192, 149, 14214, 4459, 194, 50, 3404, 10064, 186, 12678, 14859, 4657, 170, 6, 151, 183, 14952, 122, 2287, 175, 13466, 17718, 86, 10331, 46, 78, 167, 4471, 14791, 4624, 3416, 44, 10639, 17425, 15476, 4719, 26, 37, 23, 2241, 3547, 2581, 189, 13365, 9973, 190, 4500, 150, 43, 8, 42, 159, 119, 16432, 36, 14857, 153, 156, 2592, 5449, 5448, 12685, 5450, 12459, 9245, 11, 33, 2530, 188, 17721, 13747, 4640, 8238, 18481, 4653, 12682, 89, 2317, 2525, 14889, 13845, 2064, 4804, 14068, 2632, 179, 208, 193, 178, 67, 12686, 226, 12687, 14815, 2640, 18565, 2636, 31, 2614, 3, 34, 180, 18478, 13465, 124, 120, 182, 39, 4540, 166, 133, 16513, 16422, 12683, 13331, 16423, 8251, 162, 4895, 55, 68, 35, 4685, 4859, 13332, 12673, 48, 18480, 18476, 181, 2627, 85, 18496, 2537, 91, 12]\n",
      "val_np:  [3.493086143277566e-05, 3.493086143277566e-05, 3.5959113609960306e-05, 6.728818488365699e-05, 7.081230204324274e-05, 7.369767509571426e-05, 7.369767509571426e-05, 8.783180189619371e-05, 0.00010143004653152491, 0.00010292035054397034, 0.00010306149812197045, 0.00010462413187750161, 0.00010495492249675433, 0.00010613747245102666, 0.00010647501449485254, 0.00011572312365779828, 0.00011794282473108279, 0.00011993492302437622, 0.0001199833698462413, 0.0001221744892402809, 0.00012629754725965937, 0.00012629754725965937, 0.00013059958612816913, 0.00013059958612816913, 0.0001353160009760651, 0.00014040072840946555, 0.00014239964622527455, 0.0001429968651799528, 0.00014908130932061103, 0.00015149598453120878, 0.00015232552448045733, 0.00016538044481836584, 0.0001661218952150063, 0.0001661218952150063, 0.00016914499635594266, 0.00017643200151765565, 0.00017943858404342598, 0.00020056888915026566, 0.00020093774651930914, 0.0002011040806077126, 0.00020658590659968957, 0.00020880496560666018, 0.00020994480842278238, 0.00021122557506652256, 0.00022319513094221338, 0.00022692913568849376, 0.00022872841952207513, 0.00023020491910877224, 0.0002303570499120506, 0.00023249721258863452, 0.0002399667396924826, 0.00024250556718031778, 0.0002451799095734904, 0.0002483544799948363, 0.0002498284307728329, 0.0002502960496148833, 0.00026010232842669075, 0.00028014748309341733, 0.0002817003107452457, 0.00028375011718056797, 0.0002855907851065618, 0.0003047594997982946, 0.0003081483452594799, 0.0003111621461671426, 0.00031683836259978386, 0.00031791779281273693, 0.0003217908341008036, 0.00033625417553958354, 0.0003367445196378341, 0.00034652630264693946, 0.0003599501192670014, 0.00036126884564948006, 0.00036477631772629247, 0.0003685651705010217, 0.00037181118539220234, 0.00037833348957409064, 0.0003889268054908236, 0.00039830976803623797, 0.00040377332432310197, 0.00040541748104394023, 0.0004108934116997625, 0.0004151863059874383, 0.00041539192286031793, 0.00044501079213734457, 0.0004516457497724854, 0.00045197024619620665, 0.00047394370111249353, 0.00047416643975374317, 0.00048706310047355903, 0.0004911935714403795, 0.0005086962602434923, 0.0005255638092662984, 0.0005269908308337172, 0.0005280638987531965, 0.0005354585570335358, 0.0005384242807938778, 0.0005405566413919203, 0.0005447666507554414, 0.0005511409294671491, 0.0005537851920263445, 0.0005592405765601228, 0.0005634736613978334, 0.0005675002343611359, 0.000575474736892569, 0.0005845460054274297, 0.0006210318712141205, 0.0006241086919033177, 0.0006391075166478691, 0.0006517385953924004, 0.0006573859382974723, 0.000665914602427444, 0.0006664629659726028, 0.0006781755007571942, 0.0007099643206964576, 0.0007182488439747172, 0.0007248612709192075, 0.0007365414299963356, 0.0007694121122179227, 0.0008108349620878805, 0.00084066902086283, 0.0008615511965241895, 0.0008626216183521934, 0.0008844156838316947, 0.0008889913207761349, 0.0009044874550656147, 0.0009046466875114556, 0.0009098493703093368, 0.0009113587320173713, 0.0009121227520177722, 0.0009145731105501774, 0.000923344903791003, 0.0009274549842882193, 0.0009367288344733849, 0.0009443493444437682, 0.0009613037864410521, 0.0009633375412185274, 0.0009651919065592174, 0.0009704167698297596, 0.0009929389774223046, 0.0009984994273528989, 0.0010067190435637922, 0.0010089393477902807, 0.001019510171929473, 0.0010267332233950132, 0.0010269367389599564, 0.001030453861488032, 0.001034030598900523, 0.0010363557350451676, 0.0010491365903498265, 0.0010537666278219514, 0.0010897760414906373, 0.0011011673096396318, 0.0011012249788685507, 0.0011094199241677473, 0.0011278701861108093, 0.0011354155159528044, 0.0011362641330541971, 0.0011622556000496016, 0.0011664280971751483, 0.001171650003049336, 0.0011762301539145282, 0.001184796485934914, 0.0012048753393548415, 0.0012351020314090029, 0.00124052387284202, 0.0012464835712805143, 0.0012679950497556907, 0.0012690723202910426, 0.0012865552023212001, 0.0012983902355758567, 0.0013072983803538835, 0.0013184015358369428, 0.0013799401287550434, 0.0014073341798848296, 0.0014554178646080328, 0.0014945786175714353, 0.001523838007538912, 0.0015639459055980544, 0.0015696890136666685, 0.0016114150744892146, 0.0016114150744892146, 0.0016304068512700877, 0.0016353327840301338, 0.001664590773125653, 0.0016847188127165345, 0.0017129908992588217, 0.0017673285433578234, 0.001798216991759485, 0.001900265688640983, 0.0019390390226819046, 0.0019882376458308735, 0.00204011364659559, 0.002100730465765626, 0.0021036153280835296, 0.002105499033909108, 0.0021749179985457168, 0.0022627458215764198, 0.0022792090244739245, 0.0023394854317582777, 0.00234337518622706, 0.0024718967831000387, 0.002475305104572745, 0.00264474819480732, 0.0026788261173514316, 0.0027766704861834583, 0.002833003905864642, 0.002953525901250282, 0.003091768304289103, 0.003115045504040545, 0.003133329684830418, 0.0031898016351829587, 0.0034168409533422246, 0.003435984646904271, 0.0035955788290151086, 0.003897335053901977, 0.0040313739071535255, 0.004285006444640181, 0.004319676469065015, 0.004584088249307657, 0.0049637631516073165, 0.005321948678078241, 0.005512065058400062, 0.00570056825683655, 0.005959151787126048, 0.00692863114013755, 0.007033906356442153, 0.007074977431798328, 0.007282275351026994, 0.0075841576543900415, 0.007589970961708973, 0.008729777666465141, 0.008922908723239597, 0.009608181663943472, 0.009704863620355617, 0.009977996295491294, 0.010053353245051055, 0.010245399093015735, 0.011769321775481857, 0.011991201215264168, 0.012159762845732567, 0.012745364680571776, 0.012871539038653668, 0.013037211759840732, 0.013098659607386471, 0.0141973416923472, 0.014948476783787476, 0.015035112931739628, 0.01521450921723256, 0.01537309165848517, 0.017525782332985403, 0.017771083106678343, 0.019298430765428223, 0.020017332104430276, 0.020754316521270078, 0.024885664745240857, 0.36995639231860816]\n",
      "idx_key_nodes:  [6794, 6729, 14154, 6817, 10467, 6699, 619, 9097, 9981, 9272, 18437, 7488, 10754, 12976, 6838, 6731, 9098, 16826, 12765, 6793, 7330, 7067, 9231, 10399, 13456, 15331, 8743, 7507, 1438, 17093, 7246, 9270, 8015, 9528, 14522, 5712, 14049, 16346, 4071, 13364, 6692, 14058, 12783, 17548, 7413, 6724, 6814, 17833, 9571, 6807, 689, 4059, 6733, 12219, 1326, 10224, 16776, 10394, 10397, 16305, 9105, 16240, 4056, 11955, 381, 1328, 14387, 6688, 17028, 818, 13016, 9566, 7432, 8125, 6826, 7431, 6370, 5911, 4610, 2010, 11124, 13639, 807, 6806, 6828, 18709, 9331, 4058, 7494, 6722, 1275, 11791, 7433, 8403, 12411, 5622, 9092, 4042, 812, 4470, 7212, 16774, 11469, 7085, 6694, 6727, 6757, 13532, 4074, 6723, 3801, 11326, 5945, 9269, 9812, 16664, 979, 5479, 6786, 16241, 15504, 6662, 3179, 16782, 6664, 9821, 13455, 5474, 7580, 14624, 18699, 16905, 12640, 6693, 402, 18770, 6905, 13427, 3985, 18471, 8218, 12417, 5933, 3888, 5758, 5601, 5106, 5243, 14594, 13041, 7213, 5755, 16953, 17451, 4855, 13229, 6691, 706, 1331, 4767, 5662, 10885, 5304, 10956, 1289, 12864, 16209, 9185, 15719, 11016, 7521, 12938, 10411, 8005, 4634, 12638, 9570, 5481, 5623, 12223, 1366, 12226, 12260, 3997, 1855, 8208, 13457, 12957, 5108, 10730, 13381, 6973, 5006, 16371, 5402, 6837, 9829, 15320, 16689, 9360, 6848, 2592, 5654, 14823, 16696, 363, 4854, 5109, 8011, 6452, 14869, 13373, 18439, 1523, 3899, 6824, 5929, 12623, 12966, 16585, 17407, 11722, 15222, 6799, 17172, 2630, 7660, 5561, 7902, 6742, 9096, 12552, 8579, 5559, 10893, 5511, 10952, 5505, 16208, 16382, 4438, 17101, 14405, 3876, 6914, 9791, 15391, 15125, 9398, 3549, 7248, 15910, 8016, 15753, 9268, 12889, 7976, 16040, 1324, 10767, 13872, 11839, 15818, 2276, 5162, 8243, 13527, 16758, 7448, 7261, 18009, 9197, 12450, 7195, 2435, 12586, 16907, 488, 7562, 11580, 9944, 4257, 15748, 18083, 15904, 9091, 15306, 15308, 15321, 5164, 12259, 1329, 16276, 7347, 15951, 18412, 6396, 11871, 1094, 7686, 18020, 4540, 16925, 13755, 1346, 13358, 7449, 3903, 5458, 7042, 12758, 15236, 16275, 11555, 17173, 8739, 12668, 6745, 4261, 18408, 5217, 14639, 8121, 6357, 7365, 18777, 809, 839, 17265, 16916, 3411, 15139, 4259, 9499, 12235, 3914, 6696, 15199, 16906, 14403, 626, 13428, 6900, 5492, 8509, 16440, 5902, 3921, 15655, 5703, 17070, 166, 14587, 9259, 13638, 13042, 12239, 11033, 6808, 3529, 14382, 16639, 15883, 13288, 14854, 17678, 7364, 1156, 8349, 13486, 10603, 13727, 8106, 13487, 14424, 7203, 17167, 17718, 13166, 3547, 7319, 6497, 2483, 9101, 10790, 12856, 8786, 6375, 15521, 8793, 6768, 15283, 522, 3360, 5835, 7748, 1488, 18559, 6866, 10038, 16918, 1352, 9379, 6667, 516, 14372, 702, 14383, 9811, 4088, 12254, 5245, 1367, 14029, 91, 7049, 6811, 5591, 7489, 18724, 7243, 7673, 8871, 2813, 5695, 7320, 11187, 13533, 7367, 9190, 6194, 12953, 6661, 10752, 175, 5032, 3215, 15201, 16216, 5303, 10667, 7020, 12549, 9103, 15712, 15203, 17014, 17024, 16891, 15716, 1847, 2536, 6426, 5049, 7678, 10398, 517, 7025, 18496, 7136, 8014, 4624, 8503, 5005, 2472, 8138, 5663, 1845, 7379, 7138, 7050, 18077, 14741, 10066, 7087, 7346, 6614, 2890, 7395, 14376, 14339, 5913, 12, 4115, 1210, 14386, 5883, 18773, 8205, 7674, 13177, 12507, 11856, 13249, 13588, 7450, 5296, 13170, 10230, 1287, 15200, 5619, 15503, 16279, 5286, 2287, 5234, 1292, 17721, 1439, 18423, 39, 12618, 2864, 5557, 6994, 6196, 16873, 18094, 1914, 10423, 15323, 7676, 5284, 10228, 5817, 6954, 3660, 6801, 1299, 6366, 18708, 6998, 6739, 16350, 4007, 1199, 8078, 7242, 9824, 4613, 14435, 15324, 11630, 2885, 6995, 6862, 2486, 3195, 8021, 5024, 2723, 12980, 11834, 5708, 12058, 5562, 10072, 11847, 17013, 17651, 12001, 9920, 12511, 6797, 1338, 13059, 18593, 4964, 14600, 1296, 6812, 13585, 16340, 15237, 85, 15409, 985, 10958, 14518, 5729, 15897, 18485, 3941, 5898, 634, 8877, 3915, 6889, 15138, 18431, 1741, 18272, 13726, 17652, 4818, 15224, 1350, 5030, 179, 6827, 1345, 5618, 7773, 13534, 6759, 8912, 11166, 14409, 767, 7124, 14036, 13738, 13756, 831, 17079, 6073, 285, 1207, 596, 14645, 10077, 7992, 9895, 5560, 6963, 13603, 1437, 3501, 1297, 7217, 18415, 6295, 5264, 2482, 8154, 15463, 4066, 11465, 9761, 14388, 18697, 10967, 18554, 1871, 15527, 11560, 6758, 14302, 3804, 11872, 10995, 16926, 469, 9106, 12748, 6762, 7425, 8097, 14255, 5723, 6680, 1203, 2880, 11987, 15713, 12495, 5477, 15933, 4263, 15754, 17567, 16108, 15885, 16932, 874, 11369, 10489, 13465, 1194, 703, 4622, 6526, 14521, 14462, 6362, 8178, 5265, 7568, 12462, 815, 17327, 10343, 3095, 17771, 10899, 10799, 7936, 1175, 693, 8928, 6400, 5950, 5805, 12591, 12965, 2634, 9653, 5824, 5242, 15223, 16963, 15925, 11194, 14820, 6703, 519, 7561, 9606, 4657, 8944, 900, 3908, 5008, 10959, 4632, 7980, 4095, 7518, 12934, 12480, 10435, 10976, 5820, 14443, 1291, 1290, 16280, 13733, 12458, 1125, 6365, 6726, 6800, 10227, 7225, 16775, 9378, 11988, 6735, 2624, 15715, 9186, 309, 3111, 9917, 5914, 7589, 6809, 3787, 7331, 3467, 15695, 9090, 9195, 5795, 1301, 5952, 6853, 8404, 15636, 5021, 15711, 10498, 7659, 13320, 10766, 10393, 14301, 15816, 8019, 13391, 10074, 8719, 17377, 8139, 15210, 836, 12000, 13393, 6700, 1376, 7251, 18751, 5693, 15972, 7137, 17544, 15137, 3919, 16214, 12430, 1809, 16586, 1209, 8000, 6841, 16686, 14532, 11684, 17249, 5293, 3335, 15518, 6937, 2722, 10779, 7332, 6319, 17680, 820, 617, 7034, 525, 11028, 5624, 6459, 1099, 18411, 1026, 6628, 17412, 968, 6771, 6748, 9189, 12217, 6844, 8054, 16075, 6876, 6882, 5947, 2637, 6883, 6766, 8013, 12962, 5146, 450, 12851, 12451, 7573, 5247, 11441, 4973, 1882, 12620, 6916, 7517, 16514, 17547, 14479, 1578, 5057, 2534, 8565, 9801, 16721, 14899, 13015, 12214, 13737, 13019, 9651, 18571, 13451, 898, 832, 10075, 6607, 6993, 15086, 1734, 4402, 16341, 7337, 10395, 11185, 12266, 12230, 2270, 6712, 0, 13208, 1336, 8560, 11829, 8242, 15398, 5025, 8247, 2290, 17084, 14365, 15120, 7661, 11466, 3730, 10071, 2908, 18434, 5033, 3541, 5051, 4054, 10269, 13378, 1716, 11854, 5905, 6929]\n",
      "Mean kn:  171.6807142857143\n",
      "gamma:  1.0\n",
      "Overall len y:  188.175 max:  491  min:  15\n",
      "Runtime: 10.96s\n",
      "topk_train (1400, 18800)\n",
      "(512, 18800)\n"
     ]
    }
   ],
   "source": [
    "# compute the ppr vectors for train/val nodes using ACL's ApproximatePR\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "topk_train, mean_kn = ppr.topk_ppr_matrix(adj_matrix, alpha, eps, train_idx, topk, core_numbers, graph,\n",
    "                                 normalization=ppr_normalization, S=1, gamma=1.0)\n",
    "if run_val:\n",
    "    topk_val = ppr.topk_ppr_matrix(adj_matrix, alpha, eps, val_idx, topk,\n",
    "                                   normalization=ppr_normalization)\n",
    "else:\n",
    "    topk_val = None\n",
    "\n",
    "time_preprocessing = time.time() - start\n",
    "print(f\"Runtime: {time_preprocessing:.2f}s\")\n",
    "\n",
    "\n",
    "print('topk_train', topk_train.shape)\n",
    "adj_xd = adj_matrix[train_idx]\n",
    "print(adj_xd[0:0 + batch_size].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Set up model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/x5/bhlqr68144x_138bllx2mdwh0000gn/T/ipykernel_12244/72873882.py:2: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 11:10:59 (WARNING): From /var/folders/x5/bhlqr68144x_138bllx2mdwh0000gn/T/ipykernel_12244/72873882.py:2: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/x5/bhlqr68144x_138bllx2mdwh0000gn/T/ipykernel_12244/72873882.py:3: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 11:10:59 (WARNING): From /var/folders/x5/bhlqr68144x_138bllx2mdwh0000gn/T/ipykernel_12244/72873882.py:3: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tf.reset_default_graph()\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "model = pprgo.PPRGo(d, nc, hidden_size, nlayers, lr, weight_decay, dropout, adj_matrix, intermediate_layer=1000,\n",
    "                    sparse_features=type(attr_matrix) is not np.ndarray)\n",
    "\n",
    "# print(model.w0.shape)\n",
    "\n",
    "# print(model.w_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_idx:  [  0   0   0 ... 511 511 511]\n",
      "adj_matrix:  (512, 18800)\n",
      "source_adj:  (3984,)\n",
      "neighbor_adj:  (3984,)\n",
      "attr_matrix:  18800 8710\n",
      "batch_feats:  (95684, 8710)\n",
      "batch_pprw:  (95684,)\n",
      "batch_idx:  (95684,)\n",
      "source_idx:  [  0   0   0 ... 511 511 511]\n",
      "adj_matrix:  (512, 18800)\n",
      "source_adj:  (3622,)\n",
      "neighbor_adj:  (3622,)\n",
      "attr_matrix:  18800 8710\n",
      "batch_feats:  (82134, 8710)\n",
      "batch_pprw:  (82134,)\n",
      "batch_idx:  (82134,)\n",
      "source_idx:  [  0   0   0 ... 375 375 375]\n",
      "adj_matrix:  (376, 18800)\n",
      "source_adj:  (2659,)\n",
      "neighbor_adj:  (2659,)\n",
      "attr_matrix:  18800 8710\n",
      "batch_feats:  (62535, 8710)\n",
      "batch_pprw:  (62535,)\n",
      "batch_idx:  (62535,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-11 11:11:06 (INFO): Epoch 6, step 20: train 3.92516\n",
      "2022-07-11 11:11:10 (INFO): Epoch 13, step 40: train 3.23679\n",
      "2022-07-11 11:11:14 (INFO): Epoch 19, step 60: train 2.78008\n",
      "2022-07-11 11:11:18 (INFO): Epoch 26, step 80: train 2.42745\n",
      "2022-07-11 11:11:23 (INFO): Epoch 33, step 100: train 1.69532\n",
      "2022-07-11 11:11:27 (INFO): Epoch 39, step 120: train 1.45828\n",
      "2022-07-11 11:11:30 (INFO): Epoch 46, step 140: train 1.42660\n",
      "2022-07-11 11:11:34 (INFO): Epoch 53, step 160: train 1.06752\n",
      "2022-07-11 11:11:39 (INFO): Epoch 59, step 180: train 0.98348\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()\n",
    "with sess.as_default():\n",
    "    tf.compat.v1.global_variables_initializer().run()\n",
    "    nepochs, loss_hist, acc_hist, f1_hist = pprgo.train(\n",
    "            sess=sess, model=model, attr_matrix=attr_matrix,\n",
    "            train_idx=train_idx, val_idx=val_idx,\n",
    "            topk_train=topk_train, topk_val=topk_val,\n",
    "            labels=labels, adj_matrix=adj_matrix,\n",
    "            max_epochs=max_epochs, batch_size=batch_size, batch_mult_val=batch_mult_val,\n",
    "            eval_step=eval_step, early_stop=early_stop, patience=patience)\n",
    "time_training = time.time() - start\n",
    "logging.info('Training done.')\n",
    "print(f\"Runtime: {time_training:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference (val and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "predictions, time_logits, time_propagation = model.predict(\n",
    "        sess=sess, adj_matrix=adj_matrix, attr_matrix=attr_matrix, alpha=alpha,\n",
    "        nprop=nprop_inference, inf_fraction=inf_fraction,\n",
    "        ppr_normalization=ppr_normalization)\n",
    "time_inference = time.time() - start\n",
    "print(f\"Runtime: {time_inference:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_train = 100 * accuracy_score(labels[train_idx], predictions[train_idx])\n",
    "acc_val = 100 * accuracy_score(labels[val_idx], predictions[val_idx])\n",
    "acc_test = 100 * accuracy_score(labels[test_idx], predictions[test_idx])\n",
    "\n",
    "f1_train = f1_score(labels[train_idx], predictions[train_idx], average='macro')\n",
    "f1_val = f1_score(labels[val_idx], predictions[val_idx], average='macro')\n",
    "f1_test = f1_score(labels[test_idx], predictions[test_idx], average='macro')\n",
    "\n",
    "\n",
    "\n",
    "#gpu_max_bytes = tf.contrib.memory_stats.MaxBytesInUse()\n",
    "#gpu_memory = sess.run(gpu_max_bytes)\n",
    "memory = utils.get_max_memory_bytes()\n",
    "\n",
    "time_total = time_preprocessing + time_training + time_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Accuracy: Train: {acc_train:.1f}%, val: {acc_val:.1f}%, test: {acc_test:.1f}%\n",
    "F1 score: Train: {f1_train:.3f}, val: {f1_val:.3f}, test: {f1_test:.3f}\n",
    "\n",
    "Runtime: Preprocessing: {time_preprocessing:.2f}s, training: {time_training:.2f}s, inference: {time_inference:.2f}s -> total: {time_total:.2f}s\n",
    "Memory: Main: {(memory/1024) / 2**30:.2f}GB\n",
    "''')\n",
    "\n",
    "#Memory: Main: {memory / 2**30:.2f}GB, GPU: {gpu_memory / 2**30:.3f}GB"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "428b61850e5b263fbda2b97ca58cd2fe5cdcfc5a923010f6dd10a2ffb1b72031"
  },
  "kernelspec": {
   "display_name": "jupy_env",
   "language": "python",
   "name": "jupy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
